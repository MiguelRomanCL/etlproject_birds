# üéØ An√°lisis de Clusterizaci√≥n - Gu√≠a R√°pida

## üöÄ Inicio R√°pido

### Opci√≥n 1: Ejecutar con un click (Windows)
```bash
# Doble click en:
ejecutar_analisis.bat
```

### Opci√≥n 2: L√≠nea de comandos
```bash
# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Ejecutar an√°lisis
python analisis_clusterizacion_avanzado.py
```

---

## üìä ¬øQu√© hace este an√°lisis?

### Pregunta Central
> **¬øEs mejor tener 1 modelo √∫nico o m√∫ltiples modelos especializados por clusters?**

### Estrategias Comparadas

| # | Estrategia | N¬∞ Modelos | Descripci√≥n |
|---|-----------|-----------|-------------|
| 1 | **Modelo √önico** | 1 | Un solo modelo para todos los datos (baseline) |
| 2 | **Por Sexo** | 2 | Un modelo para HEMBRA, otro para MACHO |
| 3 | **Por Densidad** | ~7 | Un modelo por cada densidad de pollos/m¬≤ |
| 4 | **Por Tipo Construcci√≥n** | 3 | Tradicional / Transversal / Black Out |
| 5 | **Por Sector** | ~9 | Un modelo por cada sector geogr√°fico |
| 6 | **K-Means** | 2-10 | Clustering autom√°tico (K √≥ptimo) |
| 7 | **Hierarchical** | 2-10 | Clustering jer√°rquico |
| 8 | **DBSCAN** | Variable | Clustering por densidad |

---

## üìà M√©tricas Evaluadas

### Para Cada Estrategia se Calcula:

| M√©trica | Descripci√≥n | Mejor Valor |
|---------|-------------|-------------|
| **MAE** | Error Absoluto Medio | ‚¨áÔ∏è Menor |
| **RMSE** | Ra√≠z del Error Cuadr√°tico Medio | ‚¨áÔ∏è Menor |
| **R¬≤** | Coeficiente de Determinaci√≥n | ‚¨ÜÔ∏è Mayor |
| **CV MAE** | MAE con Validaci√≥n Cruzada | ‚¨áÔ∏è Menor |

### Interpretaci√≥n de MAE (Error en gramos)

| Rango MAE | Calidad |
|-----------|---------|
| < 3.0 | ‚≠ê‚≠ê‚≠ê Excelente |
| 3.0 - 5.0 | ‚≠ê‚≠ê Bueno |
| 5.0 - 7.0 | ‚≠ê Aceptable |
| > 7.0 | ‚ùå Necesita Mejora |

---

## üî¨ An√°lisis Estad√≠stico

### ANOVA (Analysis of Variance)
Determina si hay **diferencias significativas** entre grupos:

```
p-value < 0.05  ‚Üí  ‚úÖ Diferencias significativas (clusterizar puede ayudar)
p-value ‚â• 0.05  ‚Üí  ‚ùå No hay diferencias (modelo √∫nico es suficiente)
```

### M√©tricas de Clustering

| M√©trica | Rango | Bueno |
|---------|-------|-------|
| **Silhouette** | -1 a 1 | > 0.5 |
| **Davies-Bouldin** | 0 a ‚àû | < 1.0 |
| **Calinski-Harabasz** | 0 a ‚àû | > 100 |

---

## üìÅ Archivos Generados

### üñºÔ∏è Visualizaciones

```
üìä comparacion_estrategias.png
   ‚îú‚îÄ‚îÄ MAE por estrategia
   ‚îú‚îÄ‚îÄ RMSE por estrategia
   ‚îú‚îÄ‚îÄ R¬≤ por estrategia
   ‚îî‚îÄ‚îÄ CV MAE por estrategia

üìä kmeans_metricas.png
   ‚îú‚îÄ‚îÄ Elbow Curve (Inertia)
   ‚îú‚îÄ‚îÄ Silhouette Score
   ‚îî‚îÄ‚îÄ Davies-Bouldin Score

üìä visualizacion_clusters.png
   ‚îú‚îÄ‚îÄ K-Means en PCA
   ‚îú‚îÄ‚îÄ Hierarchical en PCA
   ‚îî‚îÄ‚îÄ Distribuci√≥n por Sexo

üìä dendrograma.png
   ‚îî‚îÄ‚îÄ √Årbol jer√°rquico de clusters
```

### üìÑ Datos y Reportes

```
üìã comparacion_estrategias.csv
   ‚îî‚îÄ‚îÄ Tabla comparativa de todas las estrategias

üìã resultados_detallados.json
   ‚îî‚îÄ‚îÄ Resultados completos con m√©tricas por grupo

üìã dataset_con_clusters.csv
   ‚îî‚îÄ‚îÄ Dataset original + asignaciones de clusters

üìã REPORTE_CLUSTERIZACION.md
   ‚îî‚îÄ‚îÄ Reporte ejecutivo con recomendaci√≥n final
```

---

## üéØ Criterios de Decisi√≥n

### ‚úÖ USAR CLUSTERIZACI√ìN si:

1. **Mejora > 5%** vs baseline
2. **ANOVA p-value < 0.05** (diferencias significativas)
3. **Silhouette Score > 0.5** (clusters bien definidos)
4. **Beneficio justifica complejidad** operacional

### ‚ö†Ô∏è EVALUAR TRADE-OFF si:

1. **Mejora 1-5%** (marginal)
2. **Recursos limitados** para mantenimiento
3. **Alta complejidad** operacional

### ‚ùå MANTENER MODELO √öNICO si:

1. **Mejora < 1%** o negativa
2. **ANOVA p-value > 0.05** (sin diferencias)
3. **Silhouette < 0.3** (clusters mal definidos)
4. **Simplicidad es prioritaria**

---

## üìä Flujo del An√°lisis

```mermaid
graph TD
    A[Cargar Datos] --> B[An√°lisis Exploratorio]
    B --> C[ANOVA por Grupos]
    C --> D{Diferencias<br/>Significativas?}
    D -->|S√≠| E[Clustering Autom√°tico]
    D -->|No| F[Modelo √önico]
    E --> G[K-Means]
    E --> H[Hierarchical]
    E --> I[DBSCAN]
    G --> J[Evaluar Modelos]
    H --> J
    I --> J
    F --> J
    J --> K[Comparar Estrategias]
    K --> L[Ranking por MAE]
    L --> M{Mejora > 5%?}
    M -->|S√≠| N[‚úÖ Recomendar Clusterizaci√≥n]
    M -->|No| O[‚ùå Recomendar Modelo √önico]
```

---

## üîß Personalizaci√≥n Avanzada

### Modificar Rango de K para K-Means
```python
# En el archivo analisis_clusterizacion_avanzado.py l√≠nea ~138
k_range = range(2, 15)  # Probar de 2 a 14 clusters
```

### Cambiar Modelo de Predicci√≥n
```python
# Reemplazar RandomForest con XGBoost
from xgboost import XGBRegressor
model = XGBRegressor(n_estimators=100, learning_rate=0.1)
```

### Ajustar DBSCAN
```python
# Mayor eps = clusters m√°s grandes
# Mayor min_samples = clusters m√°s densos
dbscan = DBSCAN(eps=3.0, min_samples=10)
```

---

## üí° Tips y Mejores Pr√°cticas

### 1. Interpretaci√≥n de Resultados
- **Priorizar MAE** sobre otras m√©tricas (m√°s interpretable)
- **Validar con cross-validation** (CV MAE)
- **Considerar R¬≤** para entender varianza explicada

### 2. Clusters √ìptimos
- **K-Means**: Usar Silhouette Score para elegir K
- **Hierarchical**: Revisar dendrograma para cortes naturales
- **DBSCAN**: Ajustar eps seg√∫n densidad esperada

### 3. Producci√≥n
- **Documentar** qu√© estrategia se eligi√≥ y por qu√©
- **Versionado** de modelos por cluster
- **Monitoreo** de drift en cada cluster

### 4. Mantenimiento
- **Re-entrenar** cuando hay suficiente data nueva
- **Validar** estabilidad de clusters en el tiempo
- **A/B Testing** antes de desplegar cambios

---

## üêõ Soluci√≥n de Problemas

### Error: ModuleNotFoundError
```bash
pip install -r requirements.txt
```

### Error: MemoryError
```python
# Reducir n_estimators o usar max_samples
rf = RandomForestRegressor(n_estimators=50, max_samples=0.5)
```

### Warning: ConvergenceWarning
```python
# Aumentar max_iter en K-Means
kmeans = KMeans(n_clusters=k, max_iter=500)
```

### Gr√°ficos no se ven
```python
# Agregar al final del script
plt.show()
```

---

## üìö Referencias

### Algoritmos
- [K-Means Clustering](https://scikit-learn.org/stable/modules/clustering.html#k-means)
- [Hierarchical Clustering](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering)
- [DBSCAN](https://scikit-learn.org/stable/modules/clustering.html#dbscan)

### M√©tricas
- [Silhouette Score](https://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient)
- [Davies-Bouldin Index](https://scikit-learn.org/stable/modules/clustering.html#davies-bouldin-index)
- [Calinski-Harabasz Index](https://scikit-learn.org/stable/modules/clustering.html#calinski-harabasz-index)

### Modelos
- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#random-forests)
- [Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html)

---

## üìû Contacto

Para preguntas o mejoras:
- **Email**: datascienceteam@tecnoandina.com
- **Documentaci√≥n**: `C:\tecnoandina\f35_modelacion2\docs`

---

**√öltima Actualizaci√≥n:** 2025-10-05  
**Versi√≥n:** 1.0  
**Proyecto:** F35 Modelaci√≥n - Predicci√≥n de Ganancia en Pollos
