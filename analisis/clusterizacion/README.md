# üìä An√°lisis Exhaustivo de Clusterizaci√≥n

## üìù Descripci√≥n

Este directorio contiene un an√°lisis completo para determinar si es conveniente crear **modelos separados por clusters** en lugar de un **modelo √∫nico** para predecir `ganancia_promedio_gramos`.

## üéØ Objetivo

Responder la pregunta: **¬øConviene clusterizar los datos y crear modelos especializados por cluster, o es mejor mantener un √∫nico modelo global?**

## üî¨ Estrategias Evaluadas

1. **Modelo √önico** (Baseline)
2. **Modelos por Sexo** (HEMBRA/MACHO)
3. **Modelos por Densidad** (pollos/m¬≤)
4. **Modelos por Tipo de Construcci√≥n** (Tradicional/Transversal/Black Out)
5. **Modelos por Sector** (alhue, bosque viejo, etc.)
6. **Modelos por K-Means Clustering** (autom√°tico)
7. **Modelos por Hierarchical Clustering** (autom√°tico)
8. **Modelos por DBSCAN** (detecci√≥n de densidad)

## üì¶ Requisitos

### Paquetes Necesarios

```bash
pip install pandas numpy matplotlib seaborn scikit-learn scipy
```

### Librer√≠as Utilizadas

#### An√°lisis de Datos
- `pandas` - Manipulaci√≥n de datos
- `numpy` - Operaciones num√©ricas

#### Visualizaci√≥n
- `matplotlib` - Gr√°ficos
- `seaborn` - Visualizaciones estad√≠sticas

#### Machine Learning
- `scikit-learn`:
  - `KMeans` - Clustering k-medias
  - `DBSCAN` - Clustering basado en densidad
  - `AgglomerativeClustering` - Clustering jer√°rquico
  - `RandomForestRegressor` - Modelo de predicci√≥n
  - `GradientBoostingRegressor` - Boosting
  - M√©tricas de clustering: Silhouette, Davies-Bouldin, Calinski-Harabasz
  - M√©tricas de regresi√≥n: MAE, RMSE, R¬≤

#### Estad√≠stica
- `scipy.stats` - An√°lisis estad√≠stico (ANOVA)
- `scipy.cluster.hierarchy` - Dendrogramas

## üöÄ Ejecuci√≥n

### Opci√≥n 1: Ejecuci√≥n Directa

```bash
python analisis_clusterizacion_avanzado.py
```

### Opci√≥n 2: Desde Jupyter Notebook

```python
%run analisis_clusterizacion_avanzado.py
```

### Opci√≥n 3: Importar como m√≥dulo

```python
import sys
sys.path.append(r'C:\tecnoandina\f35_modelacion2\analisis\clusterizacion')
from analisis_clusterizacion_avanzado import *
```

## üìä Resultados Generados

Al ejecutar el script, se generan los siguientes archivos:

### üìà Visualizaciones

1. **`comparacion_estrategias.png`**
   - Comparaci√≥n de MAE, RMSE, R¬≤ y CV MAE para todas las estrategias
   - Gr√°ficos de barras horizontales

2. **`kmeans_metricas.png`**
   - Elbow curve (Inertia)
   - Silhouette Score por K
   - Davies-Bouldin Score por K

3. **`visualizacion_clusters.png`**
   - Proyecci√≥n PCA de clusters K-Means
   - Proyecci√≥n PCA de clusters Hierarchical
   - Distribuci√≥n por Sexo en espacio PCA

4. **`dendrograma.png`**
   - Dendrograma del clustering jer√°rquico
   - Visualizaci√≥n de las √∫ltimas 30 fusiones

### üìÅ Datos

5. **`comparacion_estrategias.csv`**
   - Tabla comparativa de todas las estrategias
   - Columnas: Estrategia, N_Modelos, MAE, RMSE, R¬≤, CV_MAE

6. **`resultados_detallados.json`**
   - Resultados completos en formato JSON
   - Incluye m√©tricas por cada grupo/cluster

7. **`dataset_con_clusters.csv`**
   - Dataset original con asignaciones de clusters
   - Columnas adicionales: cluster_kmeans, cluster_hierarchical, cluster_dbscan

### üìÑ Reporte

8. **`REPORTE_CLUSTERIZACION.md`**
   - Reporte ejecutivo en Markdown
   - Resumen de hallazgos
   - Recomendaci√≥n final
   - An√°lisis estad√≠stico detallado

## üîç An√°lisis Realizados

### 1. An√°lisis Exploratorio de Grupos Naturales
- Estad√≠sticas descriptivas por grupo
- ANOVA para detectar diferencias significativas
- Identificaci√≥n de p-values

### 2. Clustering Autom√°tico

#### K-Means
- B√∫squeda del K √≥ptimo (2-10 clusters)
- M√©tricas: Silhouette, Davies-Bouldin, Calinski-Harabasz
- Selecci√≥n autom√°tica del mejor K

#### Hierarchical Clustering
- M√©todo: Ward linkage
- Dendrograma para visualizaci√≥n
- Comparaci√≥n con K-Means

#### DBSCAN
- Detecci√≥n de clusters por densidad
- Identificaci√≥n de outliers
- Par√°metros: eps=2.0, min_samples=5

### 3. Evaluaci√≥n de Modelos

Para cada estrategia se calcula:
- **MAE** (Mean Absolute Error)
- **RMSE** (Root Mean Squared Error)
- **R¬≤** (Coeficiente de determinaci√≥n)
- **CV MAE** (Cross-Validation MAE con k-fold)

Modelo utilizado: **Random Forest Regressor**
- 100 √°rboles
- Paralelizaci√≥n autom√°tica
- Validaci√≥n cruzada de 5 folds

### 4. Comparaci√≥n y Ranking

Las estrategias se ordenan por MAE (menor es mejor) y se determina:
- Mejor estrategia absoluta
- Mejora porcentual vs baseline
- Recomendaci√≥n de implementaci√≥n

## üìã Interpretaci√≥n de Resultados

### M√©tricas Clave

- **MAE < 3.0**: Excelente
- **MAE 3.0-5.0**: Bueno
- **MAE 5.0-7.0**: Aceptable
- **MAE > 7.0**: Necesita mejora

### Criterios de Decisi√≥n

#### ‚úÖ Usar Clusterizaci√≥n si:
- Mejora > 5% vs baseline
- Diferencias significativas entre grupos (ANOVA p < 0.05)
- Clusters bien definidos (Silhouette > 0.5)

#### ‚ö†Ô∏è Evaluar Trade-off si:
- Mejora 1-5% vs baseline
- Complejidad operacional alta
- Recursos limitados para mantenimiento

#### ‚ùå Mantener Modelo √önico si:
- Mejora < 1% o negativa
- ANOVA p > 0.05 (no hay diferencias significativas)
- Clusters mal definidos (Silhouette < 0.3)

## üîß Personalizaci√≥n

### Modificar Par√°metros de Clustering

```python
# K-Means
k_range = range(2, 15)  # Probar m√°s valores de K

# DBSCAN
dbscan = DBSCAN(eps=3.0, min_samples=10)  # Ajustar sensibilidad
```

### Cambiar Modelo de Predicci√≥n

```python
# Usar Gradient Boosting en lugar de Random Forest
from sklearn.ensemble import GradientBoostingRegressor
model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)
```

### Agregar Nuevas Estrategias

```python
# Ejemplo: Modelos por combinaci√≥n de variables
df['combo'] = df['sexo'] + '_' + df['tipoConstruccion']
estrategias_resultados.append(
    evaluar_estrategia(df, "MODELOS POR SEXO+TIPO", grupo_col='combo')
)
```

## üìä Output Esperado

### Consola

```
================================================================================
AN√ÅLISIS EXHAUSTIVO DE CLUSTERIZACI√ìN
================================================================================

1. Cargando datos...
   ‚úì Dataset cargado: 1234 filas, 13 columnas

2. Variables identificadas:
   ‚Ä¢ Num√©ricas: 5
   ‚Ä¢ Categ√≥ricas: 3
   ‚Ä¢ Target: ganancia_promedio_gramos

================================================================================
2. AN√ÅLISIS DE GRUPOS NATURALES
================================================================================

   üìä SEXO:
   ...
   ANOVA: F-statistic=125.4567, p-value=0.000001
   ‚úì Diferencias SIGNIFICATIVAS entre grupos (p < 0.05)

...

================================================================================
6. RECOMENDACI√ìN FINAL
================================================================================

   üèÜ MEJOR ESTRATEGIA: 2. MODELOS POR SEXO

   M√©tricas:
   ‚Ä¢ MAE: 2.8451
   ‚Ä¢ RMSE: 3.6789
   ‚Ä¢ R¬≤: 0.8567
   ‚Ä¢ N√∫mero de modelos: 2

   üìà Mejora vs Baseline: 8.34%

   ‚úÖ RECOMENDACI√ìN: Usar clusterizaci√≥n (2. MODELOS POR SEXO)
      La mejora de 8.34% justifica la complejidad adicional.
```

## üéì Conceptos Clave

### Clustering
- **K-Means**: Agrupa datos en K clusters minimizando la varianza intra-cluster
- **Hierarchical**: Construye una jerarqu√≠a de clusters (√°rbol)
- **DBSCAN**: Identifica clusters de alta densidad y outliers

### M√©tricas de Clustering
- **Silhouette Score**: Qu√© tan bien est√°n separados los clusters (-1 a 1, mayor es mejor)
- **Davies-Bouldin**: Relaci√≥n entre distancias intra e inter-cluster (menor es mejor)
- **Calinski-Harabasz**: Ratio de varianza entre vs dentro de clusters (mayor es mejor)

### ANOVA (Analysis of Variance)
- Prueba si las medias de m√∫ltiples grupos son significativamente diferentes
- p-value < 0.05: Diferencias estad√≠sticamente significativas

## üêõ Troubleshooting

### Error: "No module named 'sklearn'"
```bash
pip install scikit-learn
```

### Error: Memoria insuficiente
```python
# Reducir n_estimators o usar submuestreo
rf = RandomForestRegressor(n_estimators=50, max_samples=0.5)
```

### Warning: Convergencia de K-Means
```python
# Aumentar max_iter
kmeans = KMeans(n_clusters=k, max_iter=500, n_init=20)
```

## üìû Soporte

Para preguntas o mejoras, contactar al equipo de Data Science de Tecnoandina.

---

**√öltima actualizaci√≥n:** 2025-10-05
**Versi√≥n:** 1.0
**Autor:** Sistema de An√°lisis Automatizado
