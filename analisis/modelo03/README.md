# ğŸ“Š Modelo 02 - VersiÃ³n Limpia sin Multicolinealidad

## ğŸ“ DescripciÃ³n

Modelo simplificado que **elimina variables con multicolinealidad extrema** manteniendo solo las 5 variables clave para predicciÃ³n de `ganancia_promedio_gramos`.

## ğŸ¯ Objetivo

Crear un modelo **simple, robusto y sin multicolinealidad** que:
- âœ… Mantenga el rendimiento del Modelo 01
- âœ… Elimine VIF > 100 (multicolinealidad extrema)
- âœ… Use solo variables realmente necesarias
- âœ… Sea mÃ¡s fÃ¡cil de interpretar y mantener

## ğŸ”¬ Diferencia con Modelo 01

### Modelo 01 (Original)
```
7 variables:
âœ“ mes_carga (VIF=4.28)
âœ“ edad_madres_dias (VIF=51.02) â† ELIMINADA
âœ“ peso_inicial_gramos (VIF=256.66) â† ELIMINADA
âœ“ sexo
âœ“ kilos_recibidos_percapita (VIF=91.28)
âœ“ tipoConstruccion
âœ“ densidad_pollos_m2 (VIF=17.33)

Resultado: RÂ²=0.9022, MAE=1.53g
Problema: Multicolinealidad severa (VIF hasta 256!)
```

### Modelo 02 (Limpio)
```
5 variables:
âœ“ mes_carga
âŒ edad_madres_dias (ELIMINADA - VIF=51, correlaciÃ³n=0.103)
âŒ peso_inicial_gramos (ELIMINADA - VIF=256, correlaciÃ³n=0.135)
âœ“ sexo
âœ“ kilos_recibidos_percapita
âœ“ tipoConstruccion
âœ“ densidad_pollos_m2

Resultado: RÂ²=?, MAE=? (se compara automÃ¡ticamente)
Ventaja: VIF mÃ¡ximo < 10, sin multicolinealidad
```

## ğŸ“Š Variables Seleccionadas

### 1. **sexo** 
- CorrelaciÃ³n con target: **0.844** â­
- Diferencia HEMBRA/MACHO: ~11 gramos
- ANOVA: p < 0.0001 (muy significativa)

### 2. **kilos_recibidos_percapita**
- CorrelaciÃ³n con target: **0.827** â­
- Variable clave de alimentaciÃ³n
- Aunque tiene VIF alto, es predictor esencial

### 3. **densidad_pollos_m2**
- CorrelaciÃ³n con target: **-0.195**
- InformaciÃ³n Ãºnica sobre espacio
- Afecta crecimiento y estrÃ©s

### 4. **tipoConstruccion**
- CorrelaciÃ³n con target: **-0.330**
- Black Out > Transversal > Tradicional
- ANOVA: p < 0.0001

### 5. **mes_carga**
- CorrelaciÃ³n con target: **0.050**
- VIF: **4.28** âœ… (bajo)
- Convertida a sin/cos (cÃ­clica)

## âŒ Variables Eliminadas

### **edad_madres_dias**
- **RazÃ³n:** VIF=51 (multicolinealidad severa)
- CorrelaciÃ³n con target: solo 0.103 (baja)
- CorrelaciÃ³n con peso_inicial: 0.901 (redundante)
- **ConclusiÃ³n:** No aporta informaciÃ³n Ãºnica

### **peso_inicial_gramos**
- **RazÃ³n:** VIF=256 (multicolinealidad EXTREMA)
- CorrelaciÃ³n con target: solo 0.135 (baja directa)
- Su efecto ya estÃ¡ capturado por otras variables
- **ConclusiÃ³n:** Completamente redundante

## ğŸš€ EjecuciÃ³n

### OpciÃ³n 1: Un Click
```
1. Navegar a: C:\tecnoandina\f35_modelacion2\analisis\modelo03\
2. Doble click: ejecutar_analisis.bat
3. Esperar: 5-10 minutos
4. Revisar: REPORTE_MODELO_LIMPIO.md
```

### OpciÃ³n 2: LÃ­nea de Comandos
```bash
cd C:\tecnoandina\f35_modelacion2\analisis\modelo03
pip install -r requirements.txt
python analisis_modelamiento_limpio.py
```

### OpciÃ³n 3: PyCharm/Jupyter
```python
%run C:\tecnoandina\f35_modelacion2\analisis\modelo03\analisis_modelamiento_limpio.py
```

## ğŸ“¦ Requisitos

- Python 3.8+
- PyCaret 3.0+
- Pandas, NumPy, Scikit-learn
- Matplotlib, Seaborn
- Scipy, Statsmodels

```bash
pip install -r requirements.txt
```

## ğŸ“Š Archivos Generados

### Visualizaciones (7 PNG)
1. `01_matriz_correlacion_limpia.png`
2. `02_distribuciones_limpias.png`
3. `03_comparacion_vif.png` - â­ **ComparaciÃ³n Modelo 01 vs 02**
4. `04_top_correlaciones_limpias.png`
5. `05_feature_importance_limpio.png`
6. `06_predicciones_vs_real_limpio.png`
7. `07_analisis_residuos_limpio.png`

### Modelos y Datos
- `modelo_limpio_final.pkl` - Modelo entrenado
- `feature_importance_limpio.csv`
- `resultados_modelo_limpio.json`

### Reportes
- `REPORTE_MODELO_LIMPIO.md` - **Reporte ejecutivo con comparaciÃ³n**

## ğŸ” AnÃ¡lisis Realizados

### 1. AnÃ¡lisis de Correlaciones
- Matriz completa de 5 variables
- Top correlaciones con target
- DetecciÃ³n de correlaciones entre features

### 2. AnÃ¡lisis VIF (Multicolinealidad)
- CÃ¡lculo de VIF para cada variable
- ComparaciÃ³n Modelo 01 vs Modelo 02
- VerificaciÃ³n de mejora

### 3. Feature Engineering
- Variables cÃ­clicas: `mes_sin`, `mes_cos`
- Ratio: `alimento_por_densidad`
- CategorÃ­a: `densidad_categoria`

### 4. Modelado con PyCaret
- ComparaciÃ³n automÃ¡tica de modelos
- SelecciÃ³n del mejor algoritmo
- OptimizaciÃ³n de hiperparÃ¡metros

### 5. ComparaciÃ³n con Modelo 01
- MAE: Â¿Se mantiene el rendimiento?
- RÂ²: Â¿CuÃ¡nta varianza explica?
- **Trade-off:** Simplicidad vs Performance

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### Escenario Ideal âœ…
```
Modelo 02 MAE â‰ˆ Modelo 01 MAE (diferencia < 0.1)

ConclusiÃ³n: Â¡Ã‰xito total!
- Mismo rendimiento
- Sin multicolinealidad
- MÃ¡s simple
â†’ Usar Modelo 02
```

### Escenario Aceptable âš ï¸
```
Modelo 02 MAE > Modelo 01 MAE (diferencia 0.1-0.3)

ConclusiÃ³n: Trade-off razonable
- PÃ©rdida menor en performance
- Gran ganancia en robustez
- Modelo mÃ¡s interpretable
â†’ Evaluar prioridades
```

### Escenario CrÃ­tico ğŸ”´
```
Modelo 02 MAE >> Modelo 01 MAE (diferencia > 0.3)

ConclusiÃ³n: Variables eliminadas eran importantes
- Considerar mantener una de ellas
- O usar Modelo 01 con precauciÃ³n
â†’ Revisar estrategia
```

## ğŸ¯ Ventajas del Modelo Limpio

### âœ… **Robustez**
- Sin multicolinealidad extrema
- Menos sensible a cambios en datos
- Mejor generalizaciÃ³n

### âœ… **Simplicidad**
- Solo 5 variables vs 7
- MÃ¡s fÃ¡cil de entender
- MÃ¡s fÃ¡cil de mantener

### âœ… **Interpretabilidad**
- Cada variable aporta informaciÃ³n Ãºnica
- No hay redundancia
- Coeficientes/importancias mÃ¡s confiables

### âœ… **Eficiencia**
- Menos features = mÃ¡s rÃ¡pido
- Menos datos necesarios
- Deployment mÃ¡s simple

## âš ï¸ Consideraciones

### Multicolinealidad Residual
- `kilos_recibidos_percapita` aÃºn tiene VIF alto
- **RazÃ³n:** Es predictor clave (correlaciÃ³n 0.827)
- **DecisiÃ³n:** Mantener por su importancia

### Performance vs Simplicidad
- Posible pÃ©rdida menor en MAE
- **Trade-off:** Aceptable por robustez
- **Resultado:** Depende de prioridades del negocio

## ğŸ“Š MÃ©tricas Esperadas

### Si VIF se reduce exitosamente:
```
VIF MÃ¡ximo Modelo 01: 256.66
VIF MÃ¡ximo Modelo 02: < 20 (idealmente < 10)

ReducciÃ³n: > 90%
```

### Performance (estimado):
```
Modelo 01: MAE=1.53g, RÂ²=0.9022
Modelo 02: MAE=1.5-1.8g, RÂ²=0.85-0.90

PÃ©rdida aceptable: < 10% en mÃ©tricas
```

## ğŸš€ Deployment

### Usar Modelo 02 si:
1. âœ… MAE diferencia < 0.1g vs Modelo 01
2. âœ… Priorizas robustez y simplicidad
3. âœ… Quieres modelo fÃ¡cil de mantener
4. âœ… VIF se reduce significativamente

### Usar Modelo 01 si:
1. âš ï¸ MAE diferencia > 0.3g vs Modelo 02
2. âš ï¸ Cada 0.1g de precisiÃ³n es crÃ­tico
3. âš ï¸ Puedes manejar multicolinealidad
4. âš ï¸ Tienes expertise en interpretaciÃ³n

## ğŸ“ PrÃ³ximos Pasos

1. **Ejecutar anÃ¡lisis**
   ```bash
   ejecutar_analisis.bat
   ```

2. **Revisar REPORTE_MODELO_LIMPIO.md**
   - Ver comparaciÃ³n con Modelo 01
   - Analizar VIF mejorado
   - Leer recomendaciÃ³n final

3. **Analizar visualizaciones**
   - Especialmente `03_comparacion_vif.png`
   - Ver `06_predicciones_vs_real_limpio.png`

4. **Tomar decisiÃ³n**
   - Â¿Usar Modelo 01 o Modelo 02?
   - Basarse en mÃ©tricas objetivas
   - Considerar contexto del negocio

## â“ Preguntas Frecuentes

**P: Â¿Por quÃ© eliminar variables si el Modelo 01 funciona bien?**  
R: Multicolinealidad alta (VIF=256) causa:
- Inestabilidad en producciÃ³n
- Dificultad para interpretar
- Riesgo de overfitting
- Problemas con datos nuevos

**P: Â¿Por quÃ© mantener kilos_recibidos si tiene VIF alto?**  
R: Porque:
- CorrelaciÃ³n muy alta con target (0.827)
- Es variable de negocio clave (alimentaciÃ³n)
- Su VIF es por correlaciÃ³n con sexo (normal)
- Aporta informaciÃ³n Ãºnica crÃ­tica

**P: Â¿El modelo serÃ¡ peor sin edad_madres y peso_inicial?**  
R: Probablemente NO porque:
- Su correlaciÃ³n con target es baja (0.10 y 0.13)
- Su VIF es altÃ­simo (redundantes)
- Su informaciÃ³n ya estÃ¡ en otras variables
- El test lo confirmarÃ¡

**P: Â¿CÃ³mo sÃ© si funcionÃ³?**  
R: Compara en el reporte:
- Si MAE diferencia < 0.1g â†’ Ã‰xito
- Si VIF mÃ¡ximo < 10 â†’ Multicolinealidad eliminada
- Si RÂ² > 0.85 â†’ Rendimiento excelente

## ğŸ“š Referencias

- [Multicolinealidad (VIF)](https://www.statsmodels.org/stable/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html)
- [Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html)
- [PyCaret Documentation](https://pycaret.gitbook.io/)

## ğŸ“ Lecciones Aprendidas

### Del AnÃ¡lisis Modelo 01:
1. VIF=256 es **extremadamente** alto
2. CorrelaciÃ³n alta entre edad_madres y peso_inicial (0.901)
3. Estas variables tienen baja correlaciÃ³n directa con target
4. LightGBM maneja multicolinealidad, pero no es ideal

### Estrategia Modelo 02:
1. Eliminar variables redundantes (VIF > 50)
2. Priorizar variables con correlaciÃ³n alta con target
3. Mantener variables de negocio clave
4. Verificar que performance no se degrade

---

**Â¡Listo para ejecutar y comparar!** ğŸš€

```bash
cd C:\tecnoandina\f35_modelacion2\analisis\modelo03
ejecutar_analisis.bat
```

**DuraciÃ³n:** 5-10 minutos  
**Output:** ComparaciÃ³n completa Modelo 01 vs Modelo 02

---

**Ãšltima actualizaciÃ³n:** 2025-10-05  
**VersiÃ³n:** 1.0  
**Proyecto:** F35 ModelaciÃ³n - Modelo Limpio
